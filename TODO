TODO:

- change best rip from being part of foldername (which causes problems when renaming folders with svn when you wanna temporarily change which rip folder is used for analysis) to just being an empty file called "BEST" or something within that rip's folder, or maybe a text file called "DEFAULT" in the Track's folder that has the default rip folder's name in it
    - this won't work once we start replacing rip folders with .sort files...

- stop using "import *"

- changing the global default, say, ANIMAL in neuropy.Core on the fly doesn't seem to work

- get rid of all use of super(), replace with direct call of base class instead

- limit each Recording to only one Sort object, which is by default either the one that says 'best' in its filename, or the first one alphabetically. Override default by specifying the sorts filename as an arg to Recording.__init__ and/or .load(). Maybe add a Recording.get_sortnames method that lists available sort filenames (minus their .sort extension)
    - if you want to work with multiple Sorts at the same time, create multiple Recordings, each with a different Sort
    - this needs to work with the sort (formerly rip) folders as well, for data exported from SurfBawd

- maybe the object hierarchy or some functionality within it could be changed somehow to clarify that neuron x from Recording y is the same as neuron x from Recording z. Need to rely on the same IDs being assigned during spike sorting, but would be nice if this was then reconciled in neuropy

- use the .picker attrib of an artist (like a line) to specify whether it first a pickevent when clicked on within a certain pixel range, use this for the Schneidman scatter plots, much much easier. See pick_event_demo.py in mpl examples, or spyke.plot

- could use "fnmatch" module to do filename matching in the data folders

- add code to load .sort files

- since I'm now shuffling mseq frames in dimstim experiments, check to make sure STA code doesn't assume mseq frames are in numerical order (which I'm almost certain it doesn't). If it does, this would help explain why I haven't been finding mseq fields in rat

- tuning curves for various parameters (ori, sfreq, tfreq, phase,...), for driftbars and gratings, for both Cat 15 and dimstim 0.16
    - this should probably be some kinda TuningCurve object, analogous to all the other analysis objects I've got

- from __future__ import division

- get rid of all use of python's built-in random module, use numpy.random instead

- if an analysis method needs to return more than one object, have them return in a dictattr of results

- the whole ContrainedNeuron thing seems pretty retarted to me after not looking at it for a while... Is it really necessary? Why are there two separate sets loaded for each rip (both Neurons *and* ConstrainedNeurons)?

Netstate stuff:
    - for the time bins, try lots of different phases, see if this changes things at all
        - look if the most common states remain the most common
    - since Recordings are fairly short, either combine lots of Recordings into one (or their Experiments), or use a shorter CODEWORDLENGTH to get better stat significance for all possible words
        - add append() method to Experiment? no. din values have different meaning between Experiments
        - better to add append() to Recording? yes.
        - best to just use append() in Neuron? yes. Recording.append() will make use of this. make .spikes 2d array? no, offsets have been added
    - for common states, see if there's a gradual falloff of probs of being 1 bit, 2bit 3 bit off of that state as you move away from it in bitspace
        - maybe map out some kind of attractors in bitspace
    - maybe mess around with higher bit codes than just binary, like trinary, quaternary, which reflect more accurately the number of spikes in each bin for each neuron
    - rename all instances of binarray to binmatrix (or binmat) in cases where it's 2D (which is most of the time)
    - make plotnspikingPMFs use nsamples so you get a nice average with errorbars

- make Neuron.append() in place, and ensure whenever it's used, that's it's used on a copied Neuron
- do analyses across Recordings, using Neuron.append(), to increase significance

- add checks to Experiment.load() to see if we're dealing with Cat 15 textheaders, or the newer dimstim.SweepTable class!!
    - need to keep old buildSweepTable() f'n in dimstim.Core for backward compatibility

- replace all SLASH, / and \\ stuff by using os.path calls, like os.path.basename, os.path.dirname, os.path.join, os.path.normpath, os.path.splitdrive, os.path.splitext, os.path.split
- add a Lab object to data hierarchy, need to bump everyone else's level down one (up in number, self.level +=1)


- MPL:
    - when saving figs, automatically fill in the file name with the text of the title bar of the figure

- cross-correlograms
    - make it faster
    - add p values to peaks (% of ticks within the peak, out of all the ticks in the window)
    - do both types of shuffle correction (those would be ?)

- plot 2D matrix of cross-correlograms - see the README.wx file in mpl/examples for embedding in wx

- PSTHs
    - look more closely for 5 ms peaks. Also, looks at data recorded at lower screen refresh rates

- spike interval histograms with log scale (see Lundstrom + Fairhall 2006)

- LFPs! how to export them from surfbawd, and handle them in neuropy? forget that, access them directly with spyke

- rasters
    - multi trial single neuron raster plots
    - make rasters faster when large number of spikes on screen (instead of deleting and recreating all vlines, do so just for ones that disappear and appear?)
    - get scrolly wheel detection to zoom in and out (not possible using mpl events? have to go to wx events?)

- STC
- revcorr to sparse bars, or any stimulus really, by directly sampling VisionEgg's framebuffer - easy! just use screen.get_framebuffer_as_array - see r72 makesparsemovie file. Need to refactor Dimstim (new version, call it lowercase dimstim?) into more OOP to really do this nicely
- maybe change experiment names to include only everything after the exp id in the .srf filename, prevents cluttery repetition of recording name. In case there's only one experiment, use the full .srf filename less the leading recording id and - at the start?
    - how would this change affect an experiment name in say an rf_mapping recording, like r75?


- make PyShell/PyCrust log user input to a file
- Nah, not important?: Rips should really have ids to make them easier to reference to: r[83].rip[0] instead of r[83].rip['conservative spikes'] - this means adding id prefixes to rip folder names (or maybe suffixes: 'conservative spikes.0.rip', 'liberal spikes.1.rip', etc...). Prefixes would be better cuz they'd force sorting by id in explorer (which uses alphabetical order) - ids should be 0-based of course
- worry about conversion of ids to strings: some may be only 1 digit and may have a leading zero!
- maybe make two load() f'ns for Experiment and Neuron: one from files, and a future one from a database
- make a save() f'n that pickles the object (including any of its results, like its STA, tuning curve points, etc)? - just use IPython's %store

- more detailed experimental info:
    - Recordings
        - maybe add other info about the Recording, stored in the same folder, like skull coordinates, angles, polytrode name and type...
        - LFPs
            - maybe a .lfp binary file, one per lfp channel, with alternating timestamps and voltage (uV?), ie (int64, float64) pairs
    - Rips
        - then, maybe add something that loads info about the rip, say from some file describing the template used, and all the thresholds, exported to the same folder by SURF
        - maybe also load the template file used for the rip, perhaps also stored in the same folder
    - Neurons
        - then, maybe add something that loads the template for this neuron, as well as its modelled (or just guesstimated) location in 3D (or just 2D) coordinates in um, as well as cell type potentially





---------------------------------------
DONE:

- STAs
- codes
- Netstate stuff
    - add codeword (binary and int) popup on float over a point in the scatter plot

- cross-correlograms
- population rasters
    - add neuron id as a popup or something on mouseover on population raster plot
- various rate methods, ratePDFs
- lots of other stuff I've forgotten about
- can replace all '%s' % repr(x) with just '%r' % x
- figure out how to grab the last command typed at the interpreter, so you can set that as the figure caption, makes things nice and explicit. Current code in various gcfm().frame.SetTitle calls that sets the caption sort of guesses what was typed is a hack
- increase precision of x, y coord display in statusbar of MPL figures

MPL: - when saving figs, automatically choose .png from list

- move code to /neuropy subfolder, make a setup.py in root, keep TODO in root
- make objects in hierarchy directly accessible in parent's namespace, if that name isn't already taken.
    - e.g. ptc15.t7c.r81 instead of having to type ptc15.t['7c'].r[81]


Netstate stuff:
    - look for check cells
    - do the maximum entropy Ising model
    - see if cortical data extrapolates to the same sort of ideal network size, ~200 neurons


- need to deal with change of dimstim movie sweep time from sweeptimeMsec to sweepSec for Cat 16+
- neuron shortcut names in Recording don't seem to exist. Only exist in rips?
- _data.movies is empty after doing sta on rat data, not so after doing it on ptc15
- rename Rip to Sort, and .rip to .sort, to jive with new .sort file and (Sort)Session object in spyke
- should really get rid of annoying dependency on dimstim. That would greatly ease installation - done, except for where it's really necessary, when trying to load an Experiment object generated by dimstim >= 0.16
- get rid of dependency on dimstim, which has unavoidable dependency on VisionEgg, which requires PyOpenGL and pygame libs, which create a big headache
    - need to redefine skeletal set of classes in neuropy so you can get parsing of textheaders to work - this really just requires a bunch of classes inheriting from dictattr, I think
    - also need to redefine SweepTable - depends on Dimension - don't need all the sweeptable code, just the part that actually builds the table
    - comment out all textheader lines starting with "from dimstim"
    - need to define all possible types of experiments: Movie, Grating, etc..
    - need to define StaticParams, DynamicParams, Variable, Variables, Runs, BlankSweeps
