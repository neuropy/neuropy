TODO:

- add tuning curves
    - add Experiment.tune() method which creates a Tune object for each child neuron and combines results into a single scrollable window, like sta? - this would be lower priority
    - allow multiple dimension tuning plots
        - the first one is the x axis, and all the other ones are expressed as overplots?
        - could also do 3D plots so you could clearly see two dimensions at a time
        - could even do 3 dims in 3D, some sort of volume plot with transparency, using colour to denote response strength
    - maybe make tdelay arg a list and do overplots in different colours for each tdelay, a different colour for each
    - psths for specific values of chosen dimension?
    - raster plots split up according to all DIN, or according to just one dimension
    - ability to specify time range, in fraction or in seconds, of each sweep to consider when couting up spikes during that sweep. Eg, useful for driftbar where there's only a response in the middle 1-2 sec that you're interested in, but might be a fair bit of baseline outside of that
    - error bars on tuning curves: how to calculate them, especially when collapsing across multiple dimensions? I guess I should calculate the mean and stdev of spikes per presentation of each sweep, and then plot the SEM as the error bar for that condition (take stdev / sqrt(n) or sqrt(n-1))
        - instead of accumulating spike count for each din, should save spike rate for *each* din. Then, when collapsing over some dimensions, or keeping some fixed, take mean of all those spike rate values (assuming all din are of equal duration, if not, weight by inverse of each din's duration), and also take stdev to get SEM
- codes are not currently constrained to when stimuli are on the screen, although this shouldn't be a big deal most of the time. See recording.BaseNetstate.codes()



----------------------------------------------
OLD:

- remove all wx stuff, replace with qt stuff
    - can't seem to get Qt window creation to work from within neuropy code. Need to examine and mimic exactly how the kernel manager deals with mpl qt plot calls to create a qt window in parallel thread
    - might not be necessary in the end. Could just do everything through mpl

- convert all line endings to Unix style

- don't load all of a recording's sorts, just the default one

- when do I ever actually make use of the _movies dictattr (or previously, the _data.movies dictattr)? Am I really preventing movies from being loaded more than once? I used to use it in the commented out core.Cat15Movie(), but the dimstimskeletal.Movie() doesn't seem to use it. Is it even worth the hassle? I guess so. Every loaded recording that used a movie would otherwise load and hold its own copy of potentially the same movie data. Looks like the fake dimstim 0.16 experiment in loadCat15exp() also doesn't make use of it. Or maybe it happens to magically during the textheader execution that I'm not seeing it right now

- allow all objects to have None as parents. this way you can load a recording all on its lonesome, without having to searching up and down the tree in a complicated error prone way for its parent. Like, what if you just have a single recording directory sitting somewhere on your hard drive? Should still be able to load it all by its lonesome as say "r32" name in the namespace

- replace move file paths in read back textheaders with local movie file path as defined by core.MOVIEPATH - right now I've simply made a symbolic link in root called /mov which points to /home/mspacek/data/mov

- STA is really slow for some reason, or maybe this only happens in pyshell
    - reduce din entries down to unique values - ie get rid of repeated frame values, to make searchsorted faster - for a 40ms mseq, you'd go from 8 entries per frame (5 ms each) down to just one
    - also, maybe reduce mseq black and white pix values from 0, 255 to 0, 1, so you can accumulate in a smaller sized data type (maybe pure int instead of float, for int speed)
    - also maybe keep in mind what NVS said about finding average of a large number of floats by first adding them up and then dividing at the end: you lose precision because of the limited mantissa. Hopefully I'm adding up ints anyway, so this shouldn't apply

- auto drop into ipdb in the Qt widget on any error encountered in the ipython kernel during execution

- the whole ContrainedNeuron thing seems pretty retarted to me after not looking at it for a while... Is it really necessary? Why are there two separate sets loaded for each rip (both Neurons *and* ConstrainedNeurons)?

- change best rip from being part of foldername (which causes problems when renaming folders with svn when you wanna temporarily change which rip folder is used for analysis) to just being an empty file called "BEST" or something within that rip's folder, or maybe a text file called "DEFAULT" in the Track's folder that has the default rip folder's name in it
    - this won't work once we start replacing rip folders with .sort files...
    - maybe by default use the most recently generated .sort folder (as designated by its now auto-generated name with the datetime stamp in it), or if any of them have a DEFAULT file inside, use that one as an override
    - if .sort files exist in the path, and none of the .sort folders have a DEFAULT file inside them, use the most recently generated .sort file (again, as designated by the datetime stamp in its filename)

- NVS: xcorr RFs, find pairs that have very correlated RFs, then check if those two cells really are different cells, according to their spike waveforms. If waveforms really are different, then compare responses to natural scenes. This way, you can test if an mseq RF is in any way useful for predicting responses to nat scenes. If responses are different to nat scenes, yet RFs are the same, then visual neuroscience is hosed!

- NVS: normalize so that Rfs have the same 0 point, ie same 0 colour

- changing the global default, say, ANIMAL in neuropy.Core on the fly doesn't seem to work

- get rid of all use of super(), replace with direct call of base class instead

- limit each Recording to only one Sort object, which is by default either the one that says 'best' in its filename, or the first one alphabetically. Override default by specifying the sorts filename as an arg to Recording.__init__ and/or .load(). Maybe add a Recording.get_sortnames method that lists available sort filenames (minus their .sort extension)
    - if you want to work with multiple Sorts at the same time, create multiple Recordings, each with a different Sort
    - this needs to work with the sort (formerly rip) folders as well, for data exported from SurfBawd

- maybe the object hierarchy or some functionality within it could be changed somehow to clarify that neuron x from Recording y is the same as neuron x from Recording z. Need to rely on the same IDs being assigned during spike sorting, but would be nice if this was then reconciled in neuropy

- use the .picker attrib of an artist (like a line) to specify whether it first a pickevent when clicked on within a certain pixel range, use this for the Schneidman scatter plots, much much easier. See pick_event_demo.py in mpl examples, or spyke.plot

- could use "fnmatch" module to do filename matching in the data folders

- add code to load .sort files

- since I'm now shuffling mseq frames in dimstim experiments, check to make sure STA code doesn't assume mseq frames are in numerical order (which I'm almost certain it doesn't). If it does, this would help explain why I haven't been finding mseq fields in rat

- tuning curves for various parameters (ori, sfreq, tfreq, phase,...), for driftbars and gratings, for both Cat 15 and dimstim 0.16
    - this should probably be some kinda TuningCurve object, analogous to all the other analysis objects I've got

- from __future__ import division

- get rid of all use of python's built-in random module, use numpy.random instead

- if an analysis method needs to return more than one object, have them return in a dictattr of results


Netstate stuff:
    - for the time bins, try lots of different phases, see if this changes things at all
        - look if the most common states remain the most common
    - since Recordings are fairly short, either combine lots of Recordings into one (or their Experiments), or use a shorter CODEWORDLENGTH to get better stat significance for all possible words
        - add append() method to Experiment? no. din values have different meaning between Experiments
        - better to add append() to Recording? yes.
        - best to just use append() in Neuron? yes. Recording.append() will make use of this. make .spikes 2d array? no, offsets have been added
    - for common states, see if there's a gradual falloff of probs of being 1 bit, 2bit 3 bit off of that state as you move away from it in bitspace
        - maybe map out some kind of attractors in bitspace
    - maybe mess around with higher bit codes than just binary, like trinary, quaternary, which reflect more accurately the number of spikes in each bin for each neuron
    - rename all instances of binarray to binmatrix (or binmat) in cases where it's 2D (which is most of the time)
    - make plotnspikingPMFs use nsamples so you get a nice average with errorbars

- make Neuron.append() in place, and ensure whenever it's used, that's it's used on a copied Neuron
- do analyses across Recordings, using Neuron.append(), to increase significance

- add checks to Experiment.load() to see if we're dealing with Cat 15 textheaders, or the newer dimstim.SweepTable class!!
    - need to keep old buildSweepTable() f'n in dimstim.Core for backward compatibility

- replace all SLASH, / and \\ stuff by using os.path calls, like os.path.basename, os.path.dirname, os.path.join, os.path.normpath, os.path.splitdrive, os.path.splitext, os.path.split
- add a Lab object to data hierarchy, need to bump everyone else's level down one (up in number, self.level +=1)


- MPL:
    - when saving figs, automatically fill in the file name with the text of the title bar of the figure

- cross-correlograms
    - make it faster
    - add p values to peaks (% of ticks within the peak, out of all the ticks in the window)
    - do both types of shuffle correction (those would be ?)

- plot 2D matrix of cross-correlograms - see the README.wx file in mpl/examples for embedding in wx

- PSTHs
    - look more closely for 5 ms peaks. Also, looks at data recorded at lower screen refresh rates

- spike interval histograms with log scale (see Lundstrom + Fairhall 2006)

- LFPs! how to export them from surfbawd, and handle them in neuropy? forget that, access them directly with spyke

- rasters
    - multi trial single neuron raster plots
    - make rasters faster when large number of spikes on screen (instead of deleting and recreating all vlines, do so just for ones that disappear and appear?)
    - get scrolly wheel detection to zoom in and out (not possible using mpl events? have to go to wx events?)

- STC
- revcorr to sparse bars, or any stimulus really, by directly sampling VisionEgg's framebuffer - easy! just use screen.get_framebuffer_as_array - see r72 makesparsemovie file. Need to refactor Dimstim (new version, call it lowercase dimstim?) into more OOP to really do this nicely
- maybe change experiment names to include only everything after the exp id in the .srf filename, prevents cluttery repetition of recording name. In case there's only one experiment, use the full .srf filename less the leading recording id and - at the start?
    - how would this change affect an experiment name in say an rf_mapping recording, like r75?


- make PyShell/PyCrust log user input to a file
- Nah, not important?: Rips should really have ids to make them easier to reference to: r[83].rip[0] instead of r[83].rip['conservative spikes'] - this means adding id prefixes to rip folder names (or maybe suffixes: 'conservative spikes.0.rip', 'liberal spikes.1.rip', etc...). Prefixes would be better cuz they'd force sorting by id in explorer (which uses alphabetical order) - ids should be 0-based of course
- worry about conversion of ids to strings: some may be only 1 digit and may have a leading zero!
- maybe make two load() f'ns for Experiment and Neuron: one from files, and a future one from a database
- make a save() f'n that pickles the object (including any of its results, like its STA, tuning curve points, etc)? - just use IPython's %store

- more detailed experimental info:
    - Recordings
        - maybe add other info about the Recording, stored in the same folder, like skull coordinates, angles, polytrode name and type...
        - LFPs
            - maybe a .lfp binary file, one per lfp channel, with alternating timestamps and voltage (uV?), ie (int64, float64) pairs
    - Rips
        - then, maybe add something that loads info about the rip, say from some file describing the template used, and all the thresholds, exported to the same folder by SURF
        - maybe also load the template file used for the rip, perhaps also stored in the same folder
    - Neurons
        - then, maybe add something that loads the template for this neuron, as well as its modelled (or just guesstimated) location in 3D (or just 2D) coordinates in um, as well as cell type potentially





---------------------------------------
DONE:

- STAs
- codes
- Netstate stuff
    - add codeword (binary and int) popup on float over a point in the scatter plot

- cross-correlograms
- population rasters
    - add neuron id as a popup or something on mouseover on population raster plot
- various rate methods, ratePDFs
- lots of other stuff I've forgotten about
- can replace all '%s' % repr(x) with just '%r' % x
- figure out how to grab the last command typed at the interpreter, so you can set that as the figure caption, makes things nice and explicit. Current code in various gcfm().frame.SetTitle calls that sets the caption sort of guesses what was typed is a hack
- increase precision of x, y coord display in statusbar of MPL figures

MPL: - when saving figs, automatically choose .png from list

- move code to /neuropy subfolder, make a setup.py in root, keep TODO in root
- make objects in hierarchy directly accessible in parent's namespace, if that name isn't already taken.
    - e.g. ptc15.t7c.r81 instead of having to type ptc15.t['7c'].r[81]


Netstate stuff:
    - look for check cells
    - do the maximum entropy Ising model
    - see if cortical data extrapolates to the same sort of ideal network size, ~200 neurons


- need to deal with change of dimstim movie sweep time from sweeptimeMsec to sweepSec for Cat 16+
- neuron shortcut names in Recording don't seem to exist. Only exist in rips?
- _data.movies is empty after doing sta on rat data, not so after doing it on ptc15
- rename Rip to Sort, and .rip to .sort, to jive with new .sort file and (Sort)Session object in spyke
- should really get rid of annoying dependency on dimstim. That would greatly ease installation - done, except for where it's really necessary, when trying to load an Experiment object generated by dimstim >= 0.16
- get rid of dependency on dimstim, which has unavoidable dependency on VisionEgg, which requires PyOpenGL and pygame libs, which create a big headache
    - need to redefine skeletal set of classes in neuropy so you can get parsing of textheaders to work - this really just requires a bunch of classes inheriting from dictattr, I think
    - also need to redefine SweepTable - depends on Dimension - don't need all the sweeptable code, just the part that actually builds the table
    - comment out all textheader lines starting with "from dimstim"
    - need to define all possible types of experiments: Movie, Grating, etc..
    - need to define StaticParams, DynamicParams, Variable, Variables, Runs, BlankSweeps
- stop using "import *"
    
Tuning curves:
    - Tune object, child of Neuron - done
    - ability to fix certain parameters when building tuning curves, something like:
        neuron.tune(var='phase0', fixed={'ori':[30, 45, 60], 'sfreqCycDeg':[0.8]})
        - don't forget that when calculating which sweepis to use, to subtract orioffset from the specified fixed ori, if ori is one of the fixed vars
